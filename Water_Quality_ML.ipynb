{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/MyDrive/water_dataX.csv\""
      ],
      "metadata": {
        "id": "AMg9JoFmgHbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost tensorflow scikit-learn --quiet\n",
        "\n",
        "# ================================================\n",
        "# Step 1: Import Libraries\n",
        "# ================================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "dYcXKPUfg0dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try multiple encodings to avoid UnicodeDecodeError\n",
        "encodings = [\"utf-8\", \"latin1\", \"cp1252\", \"iso-8859-1\"]\n",
        "for enc in encodings:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding=enc)\n",
        "        print(f\"✅ Loaded successfully with encoding: {enc}\")\n",
        "        break\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Columns in dataset:\", df.columns.tolist())"
      ],
      "metadata": {
        "id": "P-9DTp88h8dZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e07a97-138f-489c-b6d5-99bda0e361de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded successfully with encoding: latin1\n",
            "Columns in dataset: ['STATION CODE', 'LOCATIONS', 'STATE', 'Temp', 'D.O. (mg/l)', 'PH', 'CONDUCTIVITY (µmhos/cm)', 'B.O.D. (mg/l)', 'NITRATENAN N+ NITRITENANN (mg/l)', 'FECAL COLIFORM (MPN/100ml)', 'TOTAL COLIFORM (MPN/100ml)Mean', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Clean Column Names\n",
        "# ================================================\n",
        "df.columns = (df.columns.astype(str)\n",
        "              .str.strip()\n",
        "              .str.lower()\n",
        "              .str.replace(r\"\\s+\", \"_\", regex=True)\n",
        "              .str.replace(r\"[\\(\\)/\\.]\", \"\", regex=True))\n"
      ],
      "metadata": {
        "id": "HMsemJ73iodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Rename known columns\n",
        "rename_map = {\n",
        "    'temp':'temp', 'temperature':'temp',\n",
        "    'd.o._mgl':'do_mg_l', 'd.o_mgl':'do_mg_l', 'do_mgl':'do_mg_l',\n",
        "    'ph':'ph',\n",
        "    'b.o.d._mgl':'bod_mg_l', 'bod_mg_l':'bod_mg_l',\n",
        "    'nitratenan_n+_nitritenann_mgl':'nitrate','nitrate':'nitrate',\n",
        "    'fecal_coliform_mpn100ml':'fecal_coliform','fecal_coliform':'fecal_coliform',\n",
        "    'total_coliform_mpn100mlmean':'total_coliform','total_coliform':'total_coliform'\n",
        "}\n",
        "existing_renames = {k:v for k,v in rename_map.items() if k in df.columns}\n",
        "df.rename(columns=existing_renames, inplace=True)\n",
        "\n",
        "# ================================================"
      ],
      "metadata": {
        "id": "Em3YZI-siwTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "cols_numeric = ['temp','do_mg_l','ph','bod_mg_l','nitrate','fecal_coliform','total_coliform']\n",
        "for c in cols_numeric:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')"
      ],
      "metadata": {
        "id": "j0C_W0D0i4ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Drop rows with essential missing values\n",
        "# ================================================\n",
        "essential_cols = [c for c in ['ph','do_mg_l','bod_mg_l'] if c in df.columns]\n",
        "print(\"Essential columns present:\", essential_cols)\n",
        "df.dropna(subset=essential_cols, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print(\"Cleaned shape:\", df.shape)"
      ],
      "metadata": {
        "id": "TSVtuLl9i_C1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fade05-385f-442b-d497-d41f095ca24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essential columns present: ['ph', 'do_mg_l']\n",
            "Cleaned shape: (1960, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ================================================\n",
        "# # Step 6: Compute Water Quality Index (Improved)\n",
        "# # ================================================\n",
        "\n",
        "# # Keep only important numeric columns\n",
        "# features_wqi = [c for c in ['ph','do_mg_l','bod_mg_l','nitrate','fecal_coliform','total_coliform'] if c in df.columns]\n",
        "# df[features_wqi] = df[features_wqi].fillna(df[features_wqi].median())\n",
        "\n",
        "# # Define standard values (based on BIS/WHO guidelines)\n",
        "# standards = {\n",
        "#     'ph': 7.0,                    # ideal neutral\n",
        "#     'do_mg_l': 7.0,               # mg/L (higher is better)\n",
        "#     'bod_mg_l': 3.0,              # mg/L (lower is better)\n",
        "#     'nitrate': 45.0,              # mg/L (WHO limit)\n",
        "#     'fecal_coliform': 500.0,      # MPN/100mL (safe)\n",
        "#     'total_coliform': 500.0       # MPN/100mL (safe)\n",
        "# }\n",
        "\n",
        "# # Assign feature weights (based on importance)\n",
        "# weights = {\n",
        "#     'ph': 0.12,\n",
        "#     'do_mg_l': 0.25,\n",
        "#     'bod_mg_l': 0.23,\n",
        "#     'nitrate': 0.15,\n",
        "#     'fecal_coliform': 0.15,\n",
        "#     'total_coliform': 0.10\n",
        "# }\n",
        "\n",
        "# # Normalize and compute sub-index (Qi) for each parameter\n",
        "# Qi = pd.DataFrame()\n",
        "\n",
        "# for feature in features_wqi:\n",
        "#     val = df[feature].astype(float)\n",
        "\n",
        "#     if feature == 'ph':\n",
        "#         # pH ideal 7, penalize deviation\n",
        "#         Qi[feature] = (100 * abs(val - standards['ph']) / 7.0).clip(0, 100)\n",
        "#     elif feature == 'do_mg_l':\n",
        "#         # Higher DO -> better quality\n",
        "#         Qi[feature] = (100 * (standards['do_mg_l'] - val) / standards['do_mg_l']).clip(0, 100)\n",
        "#     else:\n",
        "#         # Higher pollutant -> worse quality\n",
        "#         Qi[feature] = (100 * val / standards[feature]).clip(0, 100)\n",
        "\n",
        "# # Weighted WQI\n",
        "# wqi_num = sum(Qi[f] * weights[f] for f in features_wqi)\n",
        "# wqi_denom = sum(weights[f] for f in features_wqi)\n",
        "# df['wqi_composite'] = (wqi_num / wqi_denom).round(2)\n",
        "\n",
        "# # Classify water quality\n",
        "# def classify_wqi(v):\n",
        "#     if v <= 10: return 'Excellent'\n",
        "#     elif v <= 30: return 'Good'\n",
        "#     elif v <= 50: return 'Poor'\n",
        "#     elif v <= 70: return 'Very Poor'\n",
        "#     else: return 'Unsuitable'\n",
        "\n",
        "# df['quality_class'] = df['wqi_composite'].apply(classify_wqi)\n",
        "\n",
        "# print(\"\\n✅ Updated WQI Computation Done.\")\n",
        "# print(df['quality_class'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "Im5R9qaFjLQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(7,4))\n",
        "# sns.countplot(data=df, x='quality_class', palette='viridis')\n",
        "# plt.title(\"Water Quality Class Distribution (After Fix)\")\n",
        "# plt.xlabel(\"Quality Class\")\n",
        "# plt.ylabel(\"Count\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "YcPxPGgi2QHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Compute Water Quality Index (WQI)\n",
        "# ================================================\n",
        "features_wqi = [c for c in ['ph','do_mg_l','bod_mg_l','nitrate','fecal_coliform','total_coliform'] if c in df.columns]\n",
        "tmp = df[features_wqi].fillna(df[features_wqi].median())\n",
        "scaler = MinMaxScaler()\n",
        "tmp_scaled = pd.DataFrame(scaler.fit_transform(tmp), columns=tmp.columns) # Invert DO (higher=better)\n",
        "wqi_comp = np.zeros(len(tmp_scaled))\n",
        "for col in tmp_scaled.columns:\n",
        "    wqi_comp += (1 - tmp_scaled[col]) if col == 'do_mg_l' else tmp_scaled[col]\n",
        "\n",
        "wqi_comp = (wqi_comp - wqi_comp.min()) / (wqi_comp.max() - wqi_comp.min())\n",
        "df['wqi_composite'] = (wqi_comp * 100).round(2)\n",
        "\n",
        "# Classify quality\n",
        "def wqi_class(v):\n",
        "    if v <= 10: return 'Excellent'\n",
        "    elif v <= 13.5: return 'Good'\n",
        "    elif v <= 17: return 'Poor'\n",
        "    elif v <= 30: return 'Very Poor'\n",
        "    else: return 'Unsuitable'\n",
        "\n",
        "df['quality_class'] = df['wqi_composite'].apply(wqi_class)\n",
        "print(\"Target distribution:\\n\", df['quality_class'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsDlK3f-9rid",
        "outputId": "cc3b38d8-42f7-421d-9161-f8ceaf0b5da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target distribution:\n",
            " quality_class\n",
            "Poor          761\n",
            "Good          659\n",
            "Very Poor     435\n",
            "Excellent      73\n",
            "Unsuitable     32\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical  # <-- import added\n",
        "\n",
        "# Step 7: Prepare Features and Labels\n",
        "# ================================================\n",
        "\n",
        "# Filter classes with at least 2 samples\n",
        "class_counts = df['quality_class'].value_counts()\n",
        "valid_classes = class_counts[class_counts >= 2].index.tolist()\n",
        "df = df[df['quality_class'].isin(valid_classes)].reset_index(drop=True)\n",
        "\n",
        "tabular_features = [f for f in cols_numeric if f in df.columns]\n",
        "X_tab = df[tabular_features].values\n",
        "y = df['quality_class'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_cat = to_categorical(y_encoded)  # <-- now works\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# Scale tabular features\n",
        "scaler_tab = StandardScaler()\n",
        "X_tab_scaled = scaler_tab.fit_transform(X_tab)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_lstm = X_tab_scaled.reshape(X_tab_scaled.shape[0], 1, X_tab_scaled.shape[1])\n",
        "print(\"X_lstm shape:\", X_lstm.shape)\n"
      ],
      "metadata": {
        "id": "Qj7OzFxpjU_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c743cb4a-f78d-49ae-c231-a79cef606c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Excellent' 'Good' 'Poor' 'Unsuitable' 'Very Poor']\n",
            "X_lstm shape: (1960, 1, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train-Test Split\n",
        "# ================================================\n",
        "X_tab_train, X_tab_test, X_lstm_train, X_lstm_test, y_train, y_test = train_test_split(\n",
        "    X_tab_scaled, X_lstm, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(\"Training samples:\", X_tab_train.shape[0])\n",
        "print(\"Test samples:\", X_tab_test.shape[0])\n"
      ],
      "metadata": {
        "id": "2rBUgfS2kJxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87d8537-097f-4911-c591-0e211dff292e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 1568\n",
            "Test samples: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train XGBoost on Tabular Data\n",
        "# ================================================\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(le.classes_),\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_tab_train, y_train)\n",
        "xgb_pred_proba = xgb_model.predict_proba(X_tab_test)\n",
        "xgb_pred = np.argmax(xgb_pred_proba, axis=1)\n",
        "print(\"XGBoost Accuracy:\", round(accuracy_score(y_test, xgb_pred)*100,2), \"%\")\n",
        "\n",
        "# ================================================"
      ],
      "metadata": {
        "id": "kI2uohCokRvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b5afc4-0b7b-4b42-d714-b0917c4ce7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 98.72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train LSTM on Time Series\n",
        "# ================================================\n",
        "n_timesteps = X_lstm_train.shape[1]\n",
        "n_features = X_lstm_train.shape[2]\n",
        "n_classes = len(le.classes_)\n",
        "\n",
        "lstm_model = models.Sequential([\n",
        "    layers.Input(shape=(n_timesteps, n_features)),\n",
        "    layers.LSTM(64, return_sequences=False),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "lstm_model.fit(X_lstm_train, y_train, validation_split=0.2, epochs=25, batch_size=32, callbacks=[es], verbose=1)\n",
        "lstm_pred_proba = lstm_model.predict(X_lstm_test)\n",
        "lstm_pred = np.argmax(lstm_pred_proba, axis=1)\n",
        "print(\"LSTM Accuracy:\", round(accuracy_score(y_test, lstm_pred)*100,2), \"%\")\n"
      ],
      "metadata": {
        "id": "R9EDKQzHkeqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d32681-5e59-46e3-bea8-1936302921bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.0381 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "Epoch 2/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0456 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "Epoch 3/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0439 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "Epoch 4/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0461 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "Epoch 5/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0338 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "Epoch 6/25\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0421 - loss: nan - val_accuracy: 0.0350 - val_loss: nan\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "LSTM Accuracy: 3.83 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Hybrid Ensemble (XGBoost + LSTM)\n",
        "# ================================================\n",
        "# Stack predicted probabilities\n",
        "X_meta_train = np.hstack([xgb_model.predict_proba(X_tab_train), lstm_model.predict(X_lstm_train)])\n",
        "X_meta_test = np.hstack([xgb_pred_proba, lstm_pred_proba])\n",
        "\n",
        "# Handle any NaNs\n",
        "X_meta_train = np.nan_to_num(X_meta_train)\n",
        "X_meta_test = np.nan_to_num(X_meta_test)\n",
        "\n",
        "# Train meta-model\n",
        "meta_model = LogisticRegression(max_iter=500, multi_class='ovr', random_state=42)\n",
        "meta_model.fit(X_meta_train, y_train)\n",
        "meta_pred = meta_model.predict(X_meta_test)\n",
        "\n",
        "# Accuracy & Classification Report\n",
        "meta_acc = accuracy_score(y_test, meta_pred)\n",
        "print(\"Hybrid Ensemble Accuracy:\", round(meta_acc*100,2), \"%\")\n",
        "print(classification_report(y_test, meta_pred, target_names=le.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, meta_pred)\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap=\"Blues\")\n",
        "plt"
      ],
      "metadata": {
        "id": "SkFXoPymkpZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "outputId": "52eba51c-7f23-440e-a7c8-c0ab09b919b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Hybrid Ensemble Accuracy: 98.47 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       0.94      1.00      0.97        15\n",
            "        Good       0.99      0.99      0.99       132\n",
            "        Poor       0.99      0.99      0.99       152\n",
            "  Unsuitable       1.00      0.67      0.80         6\n",
            "   Very Poor       0.98      0.98      0.98        87\n",
            "\n",
            "    accuracy                           0.98       392\n",
            "   macro avg       0.98      0.93      0.95       392\n",
            "weighted avg       0.98      0.98      0.98       392\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olR8fNjVAD92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f80b9e6-22ea-49c5-fbc0-2f5e9c8a7532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Fold 1 Accuracy: 97.7%\n",
            "\n",
            "=== Fold 2 ===\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Fold 2 Accuracy: 97.45%\n",
            "\n",
            "=== Fold 3 ===\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Fold 3 Accuracy: 98.21%\n",
            "\n",
            "=== Fold 4 ===\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Fold 4 Accuracy: 98.72%\n",
            "\n",
            "=== Fold 5 ===\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Fold 5 Accuracy: 98.47%\n",
            "\n",
            "✅ Cross-Validation Results\n",
            "Accuracies per fold: [97.7, 97.45, 98.21, 98.72, 98.47]\n",
            "Mean Accuracy: 98.11 %\n",
            "Std Deviation: 0.47 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "n_splits = 5  # 5-fold CV\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "acc_scores = []\n",
        "fold = 1\n",
        "for train_index, test_index in skf.split(X_tab_scaled, y_encoded):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "\n",
        "    # Split tabular and LSTM inputs\n",
        "    X_tab_train, X_tab_test = X_tab_scaled[train_index], X_tab_scaled[test_index]\n",
        "    X_lstm_train, X_lstm_test = X_lstm[train_index], X_lstm[test_index]\n",
        "    y_train, y_test_fold = y_encoded[train_index], y_encoded[test_index]\n",
        "\n",
        "    # --- Train XGBoost ---\n",
        "    import xgboost as xgb\n",
        "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "    xgb_model.fit(X_tab_train, y_train)\n",
        "    xgb_pred_proba = xgb_model.predict_proba(X_tab_test)\n",
        "\n",
        "    # --- Train LSTM ---\n",
        "    from tensorflow.keras import models, layers, callbacks\n",
        "    n_timesteps = X_lstm_train.shape[1]\n",
        "    n_features = X_lstm_train.shape[2]\n",
        "    n_classes = len(np.unique(y_encoded))\n",
        "\n",
        "    lstm_model = models.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(64, return_sequences=False),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    lstm_model.fit(\n",
        "        X_lstm_train, y_train,\n",
        "        validation_split=0.1,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    lstm_pred_proba = lstm_model.predict(X_lstm_test)\n",
        "\n",
        "    # --- Stack predictions ---\n",
        "    # Concatenate XGBoost and LSTM probabilities as meta-features\n",
        "    X_meta_train = np.hstack([\n",
        "        xgb_model.predict_proba(X_tab_train),\n",
        "        lstm_model.predict(X_lstm_train)\n",
        "    ])\n",
        "    X_meta_test = np.hstack([xgb_pred_proba, lstm_pred_proba])\n",
        "\n",
        "    # Handle potential NaN values in meta-features\n",
        "    X_meta_train = np.nan_to_num(X_meta_train, nan=0.0)\n",
        "    X_meta_test  = np.nan_to_num(X_meta_test, nan=0.0)\n",
        "\n",
        "\n",
        "    # --- Meta-model: Logistic Regression ---\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    meta_model = LogisticRegression(max_iter=200, multi_class='ovr')\n",
        "    meta_model.fit(X_meta_train, y_train)\n",
        "\n",
        "    meta_pred = meta_model.predict(X_meta_test)\n",
        "\n",
        "    # --- Metrics ---\n",
        "    acc = accuracy_score(y_test_fold, meta_pred)\n",
        "    print(f\"Fold {fold} Accuracy: {round(acc*100, 2)}%\")\n",
        "    acc_scores.append(acc)\n",
        "    fold += 1\n",
        "\n",
        "print(\"\\n✅ Cross-Validation Results\")\n",
        "print(\"Accuracies per fold:\", [round(a*100, 2) for a in acc_scores])\n",
        "print(\"Mean Accuracy:\", round(np.mean(acc_scores)*100, 2), \"%\")\n",
        "print(\"Std Deviation:\", round(np.std(acc_scores)*100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsmsprviAF-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac8e197-9ceb-4169-b2c4-bd5180201675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 / 10 ===\n",
            "Fold 1 Accuracy: 97.45%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         7\n",
            "        Good       1.00      0.97      0.98        66\n",
            "        Poor       0.96      0.99      0.97        77\n",
            "  Unsuitable       0.75      1.00      0.86         3\n",
            "   Very Poor       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       196\n",
            "   macro avg       0.94      0.98      0.96       196\n",
            "weighted avg       0.98      0.97      0.97       196\n",
            "\n",
            "\n",
            "=== Fold 2 / 10 ===\n",
            "Fold 2 Accuracy: 98.47%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       0.88      1.00      0.93         7\n",
            "        Good       0.98      0.98      0.98        66\n",
            "        Poor       1.00      0.99      0.99        76\n",
            "  Unsuitable       1.00      0.67      0.80         3\n",
            "   Very Poor       0.98      1.00      0.99        44\n",
            "\n",
            "    accuracy                           0.98       196\n",
            "   macro avg       0.97      0.93      0.94       196\n",
            "weighted avg       0.99      0.98      0.98       196\n",
            "\n",
            "\n",
            "=== Fold 3 / 10 ===\n",
            "Fold 3 Accuracy: 98.98%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         7\n",
            "        Good       1.00      0.98      0.99        66\n",
            "        Poor       0.99      1.00      0.99        76\n",
            "  Unsuitable       1.00      0.67      0.80         3\n",
            "   Very Poor       0.98      1.00      0.99        44\n",
            "\n",
            "    accuracy                           0.99       196\n",
            "   macro avg       0.99      0.93      0.95       196\n",
            "weighted avg       0.99      0.99      0.99       196\n",
            "\n",
            "\n",
            "=== Fold 4 / 10 ===\n",
            "Fold 4 Accuracy: 95.92%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       0.88      1.00      0.93         7\n",
            "        Good       0.96      0.97      0.96        66\n",
            "        Poor       0.97      0.97      0.97        76\n",
            "  Unsuitable       1.00      0.33      0.50         3\n",
            "   Very Poor       0.95      0.95      0.95        44\n",
            "\n",
            "    accuracy                           0.96       196\n",
            "   macro avg       0.95      0.85      0.86       196\n",
            "weighted avg       0.96      0.96      0.96       196\n",
            "\n",
            "\n",
            "=== Fold 5 / 10 ===\n",
            "Fold 5 Accuracy: 98.47%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         7\n",
            "        Good       1.00      1.00      1.00        66\n",
            "        Poor       1.00      1.00      1.00        76\n",
            "  Unsuitable       0.50      0.67      0.57         3\n",
            "   Very Poor       0.98      0.95      0.97        44\n",
            "\n",
            "    accuracy                           0.98       196\n",
            "   macro avg       0.90      0.92      0.91       196\n",
            "weighted avg       0.99      0.98      0.99       196\n",
            "\n",
            "\n",
            "=== Fold 6 / 10 ===\n",
            "Fold 6 Accuracy: 97.45%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       0.88      1.00      0.93         7\n",
            "        Good       1.00      0.98      0.99        65\n",
            "        Poor       0.97      0.99      0.98        76\n",
            "  Unsuitable       1.00      0.75      0.86         4\n",
            "   Very Poor       0.95      0.95      0.95        44\n",
            "\n",
            "    accuracy                           0.97       196\n",
            "   macro avg       0.96      0.94      0.94       196\n",
            "weighted avg       0.98      0.97      0.97       196\n",
            "\n",
            "\n",
            "=== Fold 7 / 10 ===\n",
            "Fold 7 Accuracy: 99.49%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         7\n",
            "        Good       1.00      1.00      1.00        66\n",
            "        Poor       0.99      1.00      0.99        76\n",
            "  Unsuitable       1.00      1.00      1.00         4\n",
            "   Very Poor       1.00      0.98      0.99        43\n",
            "\n",
            "    accuracy                           0.99       196\n",
            "   macro avg       1.00      1.00      1.00       196\n",
            "weighted avg       0.99      0.99      0.99       196\n",
            "\n",
            "\n",
            "=== Fold 8 / 10 ===\n",
            "Fold 8 Accuracy: 97.96%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         8\n",
            "        Good       1.00      1.00      1.00        66\n",
            "        Poor       0.96      1.00      0.98        76\n",
            "  Unsuitable       1.00      0.67      0.80         3\n",
            "   Very Poor       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.98       196\n",
            "   macro avg       0.99      0.92      0.95       196\n",
            "weighted avg       0.98      0.98      0.98       196\n",
            "\n",
            "\n",
            "=== Fold 9 / 10 ===\n",
            "Fold 9 Accuracy: 98.98%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         8\n",
            "        Good       0.99      1.00      0.99        66\n",
            "        Poor       1.00      0.99      0.99        76\n",
            "  Unsuitable       1.00      0.67      0.80         3\n",
            "   Very Poor       0.98      1.00      0.99        43\n",
            "\n",
            "    accuracy                           0.99       196\n",
            "   macro avg       0.99      0.93      0.95       196\n",
            "weighted avg       0.99      0.99      0.99       196\n",
            "\n",
            "\n",
            "=== Fold 10 / 10 ===\n",
            "Fold 10 Accuracy: 99.49%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         8\n",
            "        Good       1.00      1.00      1.00        66\n",
            "        Poor       1.00      1.00      1.00        76\n",
            "  Unsuitable       0.75      1.00      0.86         3\n",
            "   Very Poor       1.00      0.98      0.99        43\n",
            "\n",
            "    accuracy                           0.99       196\n",
            "   macro avg       0.95      1.00      0.97       196\n",
            "weighted avg       1.00      0.99      1.00       196\n",
            "\n",
            "\n",
            "✅ 10-Fold Cross-Validation Results:\n",
            "Accuracies per fold: [97.45, 98.47, 98.98, 95.92, 98.47, 97.45, 99.49, 97.96, 98.98, 99.49]\n",
            "Mean Accuracy: 98.27 %\n",
            "Std Deviation: 1.05 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "\n",
        "# --- 10-fold Stratified CV setup ---\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "acc_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_index, test_index in skf.split(X_tab_scaled, y_encoded):\n",
        "    print(f\"\\n=== Fold {fold} / {n_splits} ===\")\n",
        "\n",
        "    # Split data\n",
        "    X_tab_train, X_tab_test = X_tab_scaled[train_index], X_tab_scaled[test_index]\n",
        "    X_lstm_train, X_lstm_test = X_lstm[train_index], X_lstm[test_index]\n",
        "    y_train, y_test_fold = y_encoded[train_index], y_encoded[test_index]\n",
        "\n",
        "    # --- Train XGBoost ---\n",
        "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "    xgb_model.fit(X_tab_train, y_train)\n",
        "    xgb_pred_proba = xgb_model.predict_proba(X_tab_test)\n",
        "\n",
        "    # --- Train LSTM ---\n",
        "    n_timesteps = X_lstm_train.shape[1]\n",
        "    n_features = X_lstm_train.shape[2]\n",
        "    n_classes = len(np.unique(y_encoded))\n",
        "\n",
        "    lstm_model = models.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(64, return_sequences=False),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    lstm_model.fit(\n",
        "        X_lstm_train, y_train,\n",
        "        validation_split=0.1,\n",
        "        epochs=25,\n",
        "        batch_size=32,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    lstm_pred_proba = lstm_model.predict(X_lstm_test, verbose=0)\n",
        "\n",
        "    # --- Stack outputs ---\n",
        "    X_meta_train = np.hstack([\n",
        "        xgb_model.predict_proba(X_tab_train),\n",
        "        lstm_model.predict(X_lstm_train, verbose=0)\n",
        "    ])\n",
        "    X_meta_test = np.hstack([xgb_pred_proba, lstm_pred_proba])\n",
        "\n",
        "    # Replace NaN with zeros (to prevent ValueError)\n",
        "    X_meta_train = np.nan_to_num(X_meta_train)\n",
        "    X_meta_test = np.nan_to_num(X_meta_test)\n",
        "\n",
        "    # --- Meta-model: Logistic Regression ---\n",
        "    meta_model = LogisticRegression(max_iter=200, multi_class='ovr')\n",
        "    meta_model.fit(X_meta_train, y_train)\n",
        "    meta_pred = meta_model.predict(X_meta_test)\n",
        "\n",
        "    # --- Metrics ---\n",
        "    acc = accuracy_score(y_test_fold, meta_pred)\n",
        "    print(f\"Fold {fold} Accuracy: {round(acc*100, 2)}%\")\n",
        "    acc_scores.append(acc)\n",
        "\n",
        "    # Optional: classification report\n",
        "    try:\n",
        "        print(classification_report(y_test_fold, meta_pred, target_names=le.classes_, zero_division=0))\n",
        "    except Exception:\n",
        "        print(\"⚠ Skipping detailed report (class mismatch in this fold).\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"\\n✅ 10-Fold Cross-Validation Results:\")\n",
        "print(\"Accuracies per fold:\", [round(a*100, 2) for a in acc_scores])\n",
        "print(\"Mean Accuracy:\", round(np.mean(acc_scores)*100, 2), \"%\")\n",
        "print(\"Std Deviation:\", round(np.std(acc_scores)*100, 2), \"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dytQcJ-hDiBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dce0c8-ce9e-4f48-95d7-e8c3d1453abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 / 100 ===\n",
            "Fold 1 Accuracy: 100.0%\n",
            "Fold 1 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 2 / 100 ===\n",
            "Fold 2 Accuracy: 100.0%\n",
            "Fold 2 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 3 / 100 ===\n",
            "Fold 3 Accuracy: 100.0%\n",
            "Fold 3 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 4 / 100 ===\n",
            "Fold 4 Accuracy: 100.0%\n",
            "Fold 4 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 5 / 100 ===\n",
            "Fold 5 Accuracy: 95.0%\n",
            "Fold 5 MSE: 0.2, MAE: 0.1, RMSE: 0.4472\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 6 / 100 ===\n",
            "Fold 6 Accuracy: 100.0%\n",
            "Fold 6 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 7 / 100 ===\n",
            "Fold 7 Accuracy: 100.0%\n",
            "Fold 7 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 8 / 100 ===\n",
            "Fold 8 Accuracy: 95.0%\n",
            "Fold 8 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         7\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       0.00      0.00      0.00         0\n",
            "   Very Poor       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.80      0.75      0.77        20\n",
            "weighted avg       1.00      0.95      0.97        20\n",
            "\n",
            "\n",
            "=== Fold 9 / 100 ===\n",
            "Fold 9 Accuracy: 100.0%\n",
            "Fold 9 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 10 / 100 ===\n",
            "Fold 10 Accuracy: 100.0%\n",
            "Fold 10 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 11 / 100 ===\n",
            "Fold 11 Accuracy: 100.0%\n",
            "Fold 11 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 12 / 100 ===\n",
            "Fold 12 Accuracy: 100.0%\n",
            "Fold 12 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 13 / 100 ===\n",
            "Fold 13 Accuracy: 95.0%\n",
            "Fold 13 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 14 / 100 ===\n",
            "Fold 14 Accuracy: 100.0%\n",
            "Fold 14 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 15 / 100 ===\n",
            "Fold 15 Accuracy: 100.0%\n",
            "Fold 15 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 16 / 100 ===\n",
            "Fold 16 Accuracy: 100.0%\n",
            "Fold 16 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 17 / 100 ===\n",
            "Fold 17 Accuracy: 100.0%\n",
            "Fold 17 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 18 / 100 ===\n",
            "Fold 18 Accuracy: 100.0%\n",
            "Fold 18 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 19 / 100 ===\n",
            "Fold 19 Accuracy: 90.0%\n",
            "Fold 19 MSE: 0.1, MAE: 0.1, RMSE: 0.3162\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 20 / 100 ===\n",
            "Fold 20 Accuracy: 100.0%\n",
            "Fold 20 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 21 / 100 ===\n",
            "Fold 21 Accuracy: 100.0%\n",
            "Fold 21 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 22 / 100 ===\n",
            "Fold 22 Accuracy: 100.0%\n",
            "Fold 22 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 23 / 100 ===\n",
            "Fold 23 Accuracy: 100.0%\n",
            "Fold 23 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 24 / 100 ===\n",
            "Fold 24 Accuracy: 100.0%\n",
            "Fold 24 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 25 / 100 ===\n",
            "Fold 25 Accuracy: 100.0%\n",
            "Fold 25 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 26 / 100 ===\n",
            "Fold 26 Accuracy: 100.0%\n",
            "Fold 26 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 27 / 100 ===\n",
            "Fold 27 Accuracy: 100.0%\n",
            "Fold 27 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 28 / 100 ===\n",
            "Fold 28 Accuracy: 100.0%\n",
            "Fold 28 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 29 / 100 ===\n",
            "Fold 29 Accuracy: 100.0%\n",
            "Fold 29 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 30 / 100 ===\n",
            "Fold 30 Accuracy: 95.0%\n",
            "Fold 30 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 31 / 100 ===\n",
            "Fold 31 Accuracy: 95.0%\n",
            "Fold 31 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 32 / 100 ===\n",
            "Fold 32 Accuracy: 100.0%\n",
            "Fold 32 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 33 / 100 ===\n",
            "Fold 33 Accuracy: 100.0%\n",
            "Fold 33 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 34 / 100 ===\n",
            "Fold 34 Accuracy: 100.0%\n",
            "Fold 34 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 35 / 100 ===\n",
            "Fold 35 Accuracy: 100.0%\n",
            "Fold 35 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 36 / 100 ===\n",
            "Fold 36 Accuracy: 100.0%\n",
            "Fold 36 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 37 / 100 ===\n",
            "Fold 37 Accuracy: 100.0%\n",
            "Fold 37 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 38 / 100 ===\n",
            "Fold 38 Accuracy: 100.0%\n",
            "Fold 38 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 39 / 100 ===\n",
            "Fold 39 Accuracy: 100.0%\n",
            "Fold 39 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 40 / 100 ===\n",
            "Fold 40 Accuracy: 90.0%\n",
            "Fold 40 MSE: 0.25, MAE: 0.15, RMSE: 0.5\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 41 / 100 ===\n",
            "Fold 41 Accuracy: 100.0%\n",
            "Fold 41 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 42 / 100 ===\n",
            "Fold 42 Accuracy: 95.0%\n",
            "Fold 42 MSE: 0.45, MAE: 0.15, RMSE: 0.6708\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 43 / 100 ===\n",
            "Fold 43 Accuracy: 100.0%\n",
            "Fold 43 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 44 / 100 ===\n",
            "Fold 44 Accuracy: 100.0%\n",
            "Fold 44 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 45 / 100 ===\n",
            "Fold 45 Accuracy: 100.0%\n",
            "Fold 45 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 46 / 100 ===\n",
            "Fold 46 Accuracy: 100.0%\n",
            "Fold 46 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 47 / 100 ===\n",
            "Fold 47 Accuracy: 100.0%\n",
            "Fold 47 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 48 / 100 ===\n",
            "Fold 48 Accuracy: 100.0%\n",
            "Fold 48 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 49 / 100 ===\n",
            "Fold 49 Accuracy: 100.0%\n",
            "Fold 49 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 50 / 100 ===\n",
            "Fold 50 Accuracy: 100.0%\n",
            "Fold 50 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 51 / 100 ===\n",
            "Fold 51 Accuracy: 95.0%\n",
            "Fold 51 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         7\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       0.00      0.00      0.00         0\n",
            "   Very Poor       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.80      0.75      0.77        20\n",
            "weighted avg       1.00      0.95      0.97        20\n",
            "\n",
            "\n",
            "=== Fold 52 / 100 ===\n",
            "Fold 52 Accuracy: 95.0%\n",
            "Fold 52 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 53 / 100 ===\n",
            "Fold 53 Accuracy: 95.0%\n",
            "Fold 53 MSE: 0.05, MAE: 0.05, RMSE: 0.2236\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         7\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       0.00      0.00      0.00         0\n",
            "   Very Poor       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.80      0.75      0.77        20\n",
            "weighted avg       1.00      0.95      0.97        20\n",
            "\n",
            "\n",
            "=== Fold 54 / 100 ===\n",
            "Fold 54 Accuracy: 100.0%\n",
            "Fold 54 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 55 / 100 ===\n",
            "Fold 55 Accuracy: 100.0%\n",
            "Fold 55 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 56 / 100 ===\n",
            "Fold 56 Accuracy: 100.0%\n",
            "Fold 56 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       1.00      1.00      1.00         1\n",
            "   Very Poor       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "\n",
            "=== Fold 57 / 100 ===\n",
            "Fold 57 Accuracy: 100.0%\n",
            "Fold 57 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       1.00      1.00      1.00         1\n",
            "   Very Poor       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "\n",
            "=== Fold 58 / 100 ===\n",
            "Fold 58 Accuracy: 95.0%\n",
            "Fold 58 MSE: 0.2, MAE: 0.1, RMSE: 0.4472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       0.89      1.00      0.94         8\n",
            "  Unsuitable       1.00      1.00      1.00         1\n",
            "   Very Poor       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95        20\n",
            "   macro avg       0.98      0.95      0.96        20\n",
            "weighted avg       0.96      0.95      0.95        20\n",
            "\n",
            "\n",
            "=== Fold 59 / 100 ===\n",
            "Fold 59 Accuracy: 100.0%\n",
            "Fold 59 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       1.00      1.00      1.00         1\n",
            "   Very Poor       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "\n",
            "=== Fold 60 / 100 ===\n",
            "Fold 60 Accuracy: 100.0%\n",
            "Fold 60 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       1.00      1.00      1.00         8\n",
            "  Unsuitable       1.00      1.00      1.00         1\n",
            "   Very Poor       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "\n",
            "=== Fold 61 / 100 ===\n",
            "Fold 61 Accuracy: 89.47%\n",
            "Fold 61 MSE: 0.2632, MAE: 0.1579, RMSE: 0.513\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 62 / 100 ===\n",
            "Fold 62 Accuracy: 100.0%\n",
            "Fold 62 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 63 / 100 ===\n",
            "Fold 63 Accuracy: 100.0%\n",
            "Fold 63 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 64 / 100 ===\n",
            "Fold 64 Accuracy: 100.0%\n",
            "Fold 64 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 65 / 100 ===\n",
            "Fold 65 Accuracy: 94.74%\n",
            "Fold 65 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 66 / 100 ===\n",
            "Fold 66 Accuracy: 100.0%\n",
            "Fold 66 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 67 / 100 ===\n",
            "Fold 67 Accuracy: 89.47%\n",
            "Fold 67 MSE: 0.2632, MAE: 0.1579, RMSE: 0.513\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 68 / 100 ===\n",
            "Fold 68 Accuracy: 100.0%\n",
            "Fold 68 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 69 / 100 ===\n",
            "Fold 69 Accuracy: 100.0%\n",
            "Fold 69 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 70 / 100 ===\n",
            "Fold 70 Accuracy: 94.74%\n",
            "Fold 70 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 71 / 100 ===\n",
            "Fold 71 Accuracy: 100.0%\n",
            "Fold 71 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 72 / 100 ===\n",
            "Fold 72 Accuracy: 100.0%\n",
            "Fold 72 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 73 / 100 ===\n",
            "Fold 73 Accuracy: 100.0%\n",
            "Fold 73 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 74 / 100 ===\n",
            "Fold 74 Accuracy: 94.74%\n",
            "Fold 74 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 75 / 100 ===\n",
            "Fold 75 Accuracy: 100.0%\n",
            "Fold 75 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 76 / 100 ===\n",
            "Fold 76 Accuracy: 100.0%\n",
            "Fold 76 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 77 / 100 ===\n",
            "Fold 77 Accuracy: 100.0%\n",
            "Fold 77 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 78 / 100 ===\n",
            "Fold 78 Accuracy: 94.74%\n",
            "Fold 78 MSE: 0.2105, MAE: 0.1053, RMSE: 0.4588\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 79 / 100 ===\n",
            "Fold 79 Accuracy: 94.74%\n",
            "Fold 79 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 80 / 100 ===\n",
            "Fold 80 Accuracy: 94.74%\n",
            "Fold 80 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 81 / 100 ===\n",
            "Fold 81 Accuracy: 94.74%\n",
            "Fold 81 MSE: 0.2105, MAE: 0.1053, RMSE: 0.4588\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 82 / 100 ===\n",
            "Fold 82 Accuracy: 94.74%\n",
            "Fold 82 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 83 / 100 ===\n",
            "Fold 83 Accuracy: 100.0%\n",
            "Fold 83 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 84 / 100 ===\n",
            "Fold 84 Accuracy: 100.0%\n",
            "Fold 84 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 85 / 100 ===\n",
            "Fold 85 Accuracy: 94.74%\n",
            "Fold 85 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 86 / 100 ===\n",
            "Fold 86 Accuracy: 94.74%\n",
            "Fold 86 MSE: 0.2105, MAE: 0.1053, RMSE: 0.4588\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 87 / 100 ===\n",
            "Fold 87 Accuracy: 100.0%\n",
            "Fold 87 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 88 / 100 ===\n",
            "Fold 88 Accuracy: 100.0%\n",
            "Fold 88 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 89 / 100 ===\n",
            "Fold 89 Accuracy: 100.0%\n",
            "Fold 89 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 90 / 100 ===\n",
            "Fold 90 Accuracy: 100.0%\n",
            "Fold 90 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 91 / 100 ===\n",
            "Fold 91 Accuracy: 94.74%\n",
            "Fold 91 MSE: 0.0526, MAE: 0.0526, RMSE: 0.2294\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Excellent       1.00      1.00      1.00         1\n",
            "        Good       1.00      1.00      1.00         6\n",
            "        Poor       1.00      1.00      1.00         7\n",
            "  Unsuitable       0.00      0.00      0.00         0\n",
            "   Very Poor       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.95        19\n",
            "   macro avg       0.80      0.76      0.78        19\n",
            "weighted avg       1.00      0.95      0.97        19\n",
            "\n",
            "\n",
            "=== Fold 92 / 100 ===\n",
            "Fold 92 Accuracy: 100.0%\n",
            "Fold 92 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 93 / 100 ===\n",
            "Fold 93 Accuracy: 100.0%\n",
            "Fold 93 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 94 / 100 ===\n",
            "Fold 94 Accuracy: 100.0%\n",
            "Fold 94 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 95 / 100 ===\n",
            "Fold 95 Accuracy: 100.0%\n",
            "Fold 95 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 96 / 100 ===\n",
            "Fold 96 Accuracy: 100.0%\n",
            "Fold 96 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 97 / 100 ===\n",
            "Fold 97 Accuracy: 100.0%\n",
            "Fold 97 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 98 / 100 ===\n",
            "Fold 98 Accuracy: 100.0%\n",
            "Fold 98 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 99 / 100 ===\n",
            "Fold 99 Accuracy: 100.0%\n",
            "Fold 99 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "=== Fold 100 / 100 ===\n",
            "Fold 100 Accuracy: 100.0%\n",
            "Fold 100 MSE: 0.0, MAE: 0.0, RMSE: 0.0\n",
            "⚠ Skipping detailed report (class mismatch in this fold).\n",
            "\n",
            "✅ 100-Fold Cross-Validation Results:\n",
            "Accuracies per fold: [100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 95.0, 95.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 89.47, 100.0, 100.0, 100.0, 94.74, 100.0, 89.47, 100.0, 100.0, 94.74, 100.0, 100.0, 100.0, 94.74, 100.0, 100.0, 100.0, 94.74, 94.74, 94.74, 94.74, 94.74, 100.0, 100.0, 94.74, 94.74, 100.0, 100.0, 100.0, 100.0, 94.74, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
            "Mean Accuracy: 98.51 %\n",
            "Std Deviation: 2.75 %\n",
            "\n",
            "✅ 100-Fold Cross-Validation Regression Metrics (Mean):\n",
            "Mean MSE: 0.0313\n",
            "Mean MAE: 0.02\n",
            "Mean RMSE: 0.0818\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "\n",
        "# --- 100-fold Stratified CV setup ---\n",
        "n_splits = 100\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "acc_scores = []\n",
        "mse_scores = []\n",
        "mae_scores = []\n",
        "rmse_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_index, test_index in skf.split(X_tab_scaled, y_encoded):\n",
        "    print(f\"\\n=== Fold {fold} / {n_splits} ===\")\n",
        "\n",
        "    # Split data\n",
        "    X_tab_train, X_tab_test = X_tab_scaled[train_index], X_tab_scaled[test_index]\n",
        "    X_lstm_train, X_lstm_test = X_lstm[train_index], X_lstm[test_index]\n",
        "    y_train, y_test_fold = y_encoded[train_index], y_encoded[test_index]\n",
        "\n",
        "    # Skip folds with too few samples or missing classes\n",
        "    if len(np.unique(y_test_fold)) < 2:\n",
        "        print(\"⚠ Skipping fold due to insufficient class diversity.\")\n",
        "        fold += 1\n",
        "        continue\n",
        "\n",
        "    # --- XGBoost model ---\n",
        "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "    xgb_model.fit(X_tab_train, y_train)\n",
        "    xgb_pred_proba = xgb_model.predict_proba(X_tab_test)\n",
        "\n",
        "    # --- LSTM model ---\n",
        "    n_timesteps = X_lstm_train.shape[1]\n",
        "    n_features = X_lstm_train.shape[2]\n",
        "    n_classes = len(np.unique(y_encoded))\n",
        "\n",
        "    lstm_model = models.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(64, return_sequences=False),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "    lstm_model.fit(\n",
        "        X_lstm_train, y_train,\n",
        "        validation_split=0.1,\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    lstm_pred_proba = lstm_model.predict(X_lstm_test, verbose=0)\n",
        "\n",
        "    # --- Stack model outputs ---\n",
        "    X_meta_train = np.hstack([\n",
        "        xgb_model.predict_proba(X_tab_train),\n",
        "        lstm_model.predict(X_lstm_train, verbose=0)\n",
        "    ])\n",
        "    X_meta_test = np.hstack([xgb_pred_proba, lstm_pred_proba])\n",
        "\n",
        "    # Replace NaN/inf with zeros\n",
        "    X_meta_train = np.nan_to_num(X_meta_train)\n",
        "    X_meta_test = np.nan_to_num(X_meta_test)\n",
        "\n",
        "    # --- Meta learner ---\n",
        "    meta_model = LogisticRegression(max_iter=200, multi_class='ovr')\n",
        "    meta_model.fit(X_meta_train, y_train)\n",
        "    meta_pred = meta_model.predict(X_meta_test)\n",
        "\n",
        "    # --- Metrics ---\n",
        "    acc = accuracy_score(y_test_fold, meta_pred)\n",
        "    mse = mean_squared_error(y_test_fold, meta_pred)\n",
        "    mae = mean_absolute_error(y_test_fold, meta_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"Fold {fold} Accuracy: {round(acc*100, 2)}%\")\n",
        "    print(f\"Fold {fold} MSE: {round(mse, 4)}, MAE: {round(mae, 4)}, RMSE: {round(rmse, 4)}\")\n",
        "\n",
        "    acc_scores.append(acc)\n",
        "    mse_scores.append(mse)\n",
        "    mae_scores.append(mae)\n",
        "    rmse_scores.append(rmse)\n",
        "\n",
        "    try:\n",
        "        print(classification_report(y_test_fold, meta_pred, target_names=le.classes_, zero_division=0))\n",
        "    except Exception:\n",
        "        print(\"⚠ Skipping detailed report (class mismatch in this fold).\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"\\n✅ 100-Fold Cross-Validation Results:\")\n",
        "print(\"Accuracies per fold:\", [round(a*100, 2) for a in acc_scores])\n",
        "print(\"Mean Accuracy:\", round(np.mean(acc_scores)*100, 2), \"%\")\n",
        "print(\"Std Deviation:\", round(np.std(acc_scores)*100, 2), \"%\")\n",
        "\n",
        "print(\"\\n✅ 100-Fold Cross-Validation Regression Metrics (Mean):\")\n",
        "print(\"Mean MSE:\", round(np.mean(mse_scores), 4))\n",
        "print(\"Mean MAE:\", round(np.mean(mae_scores), 4))\n",
        "print(\"Mean RMSE:\", round(np.mean(rmse_scores), 4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_scores = []\n",
        "mse_scores = []\n",
        "mae_scores = []\n",
        "rmse_scores = []\n",
        "\n",
        "# inside the loop\n",
        "acc_scores.append(acc)\n",
        "mse_scores.append(mse)\n",
        "mae_scores.append(mae)\n",
        "rmse_scores.append(rmse)\n",
        "\n",
        "# after the loop\n",
        "print(\"\\n✅ 100-Fold Cross-Validation Summary:\")\n",
        "print(\"Mean Accuracy:\", round(np.mean(acc_scores)*100, 2), \"%\")\n",
        "print(\"Mean MSE:\", round(np.mean(mse_scores), 4))\n",
        "print(\"Mean MAE:\", round(np.mean(mae_scores), 4))\n",
        "print(\"Mean RMSE:\", round(np.mean(rmse_scores), 4))\n",
        "\n"
      ],
      "metadata": {
        "id": "yfyyuTa9lofS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f80cc36-f06d-45cb-8a3d-677b12d9327c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 100-Fold Cross-Validation Summary:\n",
            "Mean Accuracy: 100.0 %\n",
            "Mean MSE: 0.0\n",
            "Mean MAE: 0.0\n",
            "Mean RMSE: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# --- Create directory if not exists ---\n",
        "save_dir = \"/content/drive/MyDrive/models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# --- Save LSTM Model ---\n",
        "try:\n",
        "    lstm_model.save(f\"{save_dir}/lstm_water_quality.h5\")\n",
        "    print(\"✅ LSTM model saved.\")\n",
        "except NameError:\n",
        "    print(\"⚠️ LSTM model not found. Train it before saving.\")\n",
        "\n",
        "# --- Save XGBoost Model ---\n",
        "try:\n",
        "    xgb_model.save_model(f\"{save_dir}/xgboost_water_quality.json\")\n",
        "    print(\"✅ XGBoost model saved.\")\n",
        "except NameError:\n",
        "    print(\"⚠️ XGBoost model not found. Train it before saving.\")\n",
        "\n",
        "# --- Save Meta-Model (Logistic Regression) ---\n",
        "try:\n",
        "    joblib.dump(meta_model, f\"{save_dir}/meta_logistic.pkl\")\n",
        "    print(\"✅ Meta-model saved.\")\n",
        "except NameError:\n",
        "    print(\"⚠️ Meta-model not found. Train it before saving.\")\n",
        "\n",
        "# --- Save LabelEncoder and Scaler ---\n",
        "try:\n",
        "    joblib.dump(le, f\"{save_dir}/label_encoder.pkl\")\n",
        "    joblib.dump(scaler_tab, f\"{save_dir}/scaler.pkl\")\n",
        "    print(\"✅ LabelEncoder and Scaler saved.\")\n",
        "except NameError:\n",
        "    print(\"⚠️ LabelEncoder or Scaler not found. Please run training section first.\")\n",
        "\n",
        "print(\"\\n🎯 Model saving process completed.\")\n"
      ],
      "metadata": {
        "id": "1KO5o8qM7GlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b5a297-e5de-499d-99f5-b613873c185c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LSTM model saved.\n",
            "✅ XGBoost model saved.\n",
            "✅ Meta-model saved.\n",
            "✅ LabelEncoder and Scaler saved.\n",
            "\n",
            "🎯 Model saving process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeeZzsC6tLo7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}